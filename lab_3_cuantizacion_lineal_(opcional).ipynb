{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/wakusoftware/intro_cuantizacion/blob/master/lab_3_cuantizacion_lineal_(opcional).ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Cuantización Lineal en Pytorch (Opcional)\n",
    "\n",
    "En esta sección, implementaremos la cuantización lineal para tensores de PyTorch."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introducción\n",
    "\n",
    "La cuantización es una técnica utilizada para reducir la precisión de los números en los modelos de aprendizaje automático, con el objetivo de disminuir el uso de memoria y aumentar la velocidad de inferencia. La **cuantización lineal** es un método que mapea valores de punto flotante (fp32) a un rango más pequeño utilizando números enteros (int8). Este laboratorio te guiará a través de los conceptos básicos y te proporcionará ejemplos prácticos en PyTorch.\n",
    "\n",
    "## Conceptos Básicos de la Cuantización Lineal\n",
    "\n",
    "### ¿Qué es la Cuantización Lineal?\n",
    "\n",
    "La cuantización lineal transforma los valores continuos (float32) en un conjunto discreto de valores (int8). Esta transformación se realiza mediante una operación matemática simple que involucra dos parámetros clave: **escala** y **punto cero**.\n",
    "\n",
    "### Escala (Scale)\n",
    "\n",
    "La **escala** es un factor que determina la resolución de la cuantización. Es como un \"multiplicador\" que ajusta el rango de los valores de punto flotante para que se puedan representar en el rango más pequeño de valores enteros.\n",
    "\n",
    "- Imagina que tienes un termómetro que mide de 0 a 100 grados y quieres representar esa temperatura en una escala más pequeña de 0 a 10. La escala sería 10 (es decir, cada unidad en la nueva escala representa 10 grados en la escala original).\n",
    "\n",
    "### Punto Cero (Zero Point)\n",
    "\n",
    "El **punto cero** es un valor de desplazamiento que asegura que el rango de valores int8 mapea correctamente al rango de valores fp32.\n",
    "\n",
    "- Siguiendo con el ejemplo del termómetro, si decides que el valor 0 en la nueva escala (0 a 10) debe corresponder a 30 grados en la escala original, el punto cero sería 3 (es decir, 30 grados menos la escala de 10).\n",
    "\n",
    "En términos matemáticos, la cuantización se realiza con la siguiente fórmula:\n",
    "\n",
    "\\[ \\text{valor\\_cuantizado} = \\text{round}(\\text{valor\\_flotante} / \\text{escala}) + \\text{punto\\_cero} \\]\n",
    "\n",
    "Y la descuantización se realiza con:\n",
    "\n",
    "\\[ \\text{valor\\_flotante} = (\\text{valor\\_cuantizado} - \\text{punto\\_cero}) \\times \\text{escala} \\]\n",
    "\n",
    "### Beneficios de la Cuantización Lineal\n",
    "\n",
    "- **Reducción del uso de memoria**: Los modelos cuantizados utilizan menos memoria.\n",
    "- **Aumento de la velocidad**: Los cálculos en int8 son más rápidos en comparación con fp32.\n",
    "- **Menor consumo de energía**: Los dispositivos de hardware optimizados para cuantización pueden consumir menos energía.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ejemplo Práctico en PyTorch\n",
    "\n",
    "### Paso 1: Configuración del Entorno\n",
    "\n",
    "Primero, asegúrate de tener los paquetes instalados. Puedes instalarlos así:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Si estas usando Google Colab, no es necesario instalar los paquetes ya que Colab ya los tiene instalados."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Paso 2: Definir una Función de Cuantización Lineal\n",
    "A continuación, definimos una función que realizará la cuantización lineal de un tensor de punto flotante a un tensor de enteros de 8 bits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "source": [
    "import torch\n",
    "\n",
    "def linear_quantize(tensor, scale, zero_point, dtype=torch.int8):\n",
    "    \"\"\"\n",
    "    Aplica cuantización lineal a un tensor.\n",
    "\n",
    "    Args:\n",
    "    tensor (torch.Tensor): El tensor de punto flotante a cuantizar.\n",
    "    scale (float): El factor de escala para la cuantización.\n",
    "    zero_point (int): El punto cero para la cuantización.\n",
    "    dtype (torch.dtype): El tipo de datos del tensor cuantizado.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: El tensor cuantizado.\n",
    "    \"\"\"\n",
    "    quantized_tensor = torch.round(tensor / scale) + zero_point\n",
    "    quantized_tensor = quantized_tensor.clamp(0, 255).to(dtype)\n",
    "    return quantized_tensor\n"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Paso 3: Cuantización y Descuantización de un Tensor\n",
    "En este ejemplo, cuantizaremos y luego descuantizaremos un tensor de muestra"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Crear un tensor de muestra\n",
    "tensor_fp32 = torch.tensor([1.0, 2.5, 3.0, 4.5, 5.0], dtype=torch.float32)\n",
    "\n",
    "# Definir los parámetros de cuantización\n",
    "scale = 0.1\n",
    "zero_point = 128\n",
    "\n",
    "# Aplicar la cuantización lineal\n",
    "tensor_int8 = linear_quantize(tensor_fp32, scale, zero_point)\n",
    "\n",
    "print(\"Tensor cuantizado (int8):\", tensor_int8)\n",
    "\n",
    "# Función de descuantización\n",
    "def linear_dequantize(tensor, scale, zero_point):\n",
    "    \"\"\"\n",
    "    Aplica descuantización lineal a un tensor.\n",
    "\n",
    "    Args:\n",
    "    tensor (torch.Tensor): El tensor cuantizado.\n",
    "    scale (float): El factor de escala utilizado para la cuantización.\n",
    "    zero_point (int): El punto cero utilizado para la cuantización.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: El tensor descuantizado.\n",
    "    \"\"\"\n",
    "    dequantized_tensor = (tensor.to(torch.float32) - zero_point) * scale\n",
    "    return dequantized_tensor\n",
    "\n",
    "# Aplicar la descuantización lineal\n",
    "tensor_dequantized = linear_dequantize(tensor_int8, scale, zero_point)\n",
    "\n",
    "print(\"Tensor descuantizado (fp32):\", tensor_dequantized)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explicación del Código\n",
    "\n",
    "- Función de Cuantización Lineal: La función linear_quantize toma un tensor de punto flotante, un factor de escala, un punto cero y devuelve un tensor cuantizado en int8.\n",
    "-\n",
    "- Cuantización del Tensor: El tensor de punto flotante tensor_fp32 se cuantiza utilizando la función linear_quantize.\n",
    "- Función de Descuantización Lineal: La función linear_dequantize toma un tensor cuantizado y lo convierte de nuevo a un tensor de punto flotante utilizando los mismos parámetros de escala y punto cero.\n",
    "- Descuantización del Tensor: El tensor cuantizado tensor_int8 se descuantiza utilizando la función linear_dequantize.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Diferencias entre Cuantización Simétrica y Asimétrica\n",
    "\n",
    "### Cuantización Simétrica\n",
    "\n",
    "En la **cuantización simétrica**, el rango de los valores de punto flotante se mapea de manera uniforme alrededor del cero. Esto significa que el valor cero en la representación cuantizada corresponde al valor cero en la representación de punto flotante. La fórmula para la cuantización simétrica es:\n",
    "\n",
    "\\[ \\text{valor\\_cuantizado} = \\text{round}(\\text{valor\\_flotante} / \\text{escala}) \\]\n",
    "\n",
    "- **Escala (scale)**: Es un factor que determina la resolución de la cuantización. En cuantización simétrica, la escala es el mismo factor tanto para los valores positivos como para los negativos.\n",
    "- **Punto cero (zero point)**: En cuantización simétrica, el punto cero es siempre 0.\n",
    "\n",
    "**Ventajas**:\n",
    "- La implementación es más sencilla, ya que no hay desplazamiento adicional.\n",
    "- Es adecuada cuando los datos de entrada están centrados alrededor de cero.\n",
    "\n",
    "**Desventajas**:\n",
    "- No es eficiente si los datos tienen un rango asimétrico, ya que puede desperdiciar parte del rango de representación.\n",
    "\n",
    "### Cuantización Asimétrica\n",
    "\n",
    "En la **cuantización asimétrica**, el rango de los valores de punto flotante se mapea de manera que el punto cero puede no ser cero. Esto permite un mejor aprovechamiento del rango de representación, especialmente cuando los datos no están centrados alrededor de cero. La fórmula para la cuantización asimétrica es:\n",
    "\n",
    "\\[ \\text{valor\\_cuantizado} = \\text{round}(\\text{valor\\_flotante} / \\text{escala}) + \\text{punto\\_cero} \\]\n",
    "\n",
    "- **Escala (scale)**: Determina la resolución de la cuantización. En cuantización asimétrica, puede ser diferente para los valores positivos y negativos.\n",
    "- **Punto cero (zero point)**: Es un desplazamiento que asegura que el rango de valores cuantizados mapea correctamente al rango de valores de punto flotante.\n",
    "\n",
    "**Ventajas**:\n",
    "- Mejor utilización del rango de representación, especialmente para datos con distribución asimétrica.\n",
    "- Puede reducir el error de cuantización en modelos donde los datos de entrada no están centrados alrededor de cero."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- En este laboratorio, hemos utilizado cuantización lineal asimétrica, ya que incluimos tanto la escala como el punto cero en la fórmula de cuantización:\n",
    "\n",
    "\\[ \\text{valor\\_cuantizado} = \\text{round}(\\text{valor\\_flotante} / \\text{escala}) + \\text{punto\\_cero} \\]\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "kd9Q2SD0MJGw",
    "E1palk4uRQX9",
    "oAexFpXiX1PW",
    "ChnEqFPYMn3p",
    "MFx2m7RmzRd5",
    "LbPjb9OOi0Xp",
    "6WopWDYWQr7X",
    "LYfTqh_VMTzT",
    "4YZP-9XTNkur",
    "dpKLMdCYvT_W",
    "2hoC5tcJznoI",
    "S68UGldKRnJc",
    "Y4Qfalu9vtHv",
    "WJN9IfVLTFNd",
    "qC0X9ux6JEmi",
    "AkwpMs-C5ccj",
    "EDpd5Te632KY",
    "JA1-rcLz4t4D",
    "kROAEGfdDsau",
    "oo4BCLpsDw3t",
    "h2gK-eALFc8U",
    "yDin7Rm6Dzqu",
    "X6J9ZiyHWzHa",
    "qUw1gQUu5yIe",
    "vGll7vBT6BGI",
    "Cl3AUuDuAH5w",
    "8NS1TnQt6E6v",
    "vcRy85lACotg"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
